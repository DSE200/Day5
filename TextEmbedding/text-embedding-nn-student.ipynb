{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why text embeddings for prediction\n",
    "\n",
    "Using a pretrained text embedding model is an easy way to turn variable-length product reviews into dense numeric vectors that encode semantics, allowing a compact neural network to learn a recommendation signal without relearning the entire language structure from scratch. This approach is absolutely doable for a classroom demo and keeps the workflow focused on the predictive task instead of low-level NLP feature engineering.\n"
   ],
   "id": "ff55cf2848d6161e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset choice\n",
    "\n",
    "We'll use Kaggle's [Women's E-Commerce Clothing Reviews](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews) dataset, which contains each review's free-text content and a `Recommended IND` label. Download `Womens Clothing E-Commerce Reviews.csv` from Kaggle, place it at `TextEmbedding/data/womens_clothing_reviews.csv`, and the notebook will predict whether a review recommends the product by feeding embeddings into a neural network.\n"
   ],
   "id": "2090144b69098ffa"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n"
   ],
   "id": "e26dabc43f9dd0dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nicapotato/womens-ecommerce-clothing-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "df = pd.read_csv(\n",
    "    path+\"/Womens Clothing E-Commerce Reviews.csv\",\n",
    "    usecols=[\"Review Text\", \"Recommended IND\"]\n",
    ")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# TODO: load `Womens Clothing E-Commerce Reviews.csv`, keep the review text + Recommended IND columns,\n",
    "#       drop rows with missing/blank text, and end up with a DataFrame that exposes two new columns:\n",
    "#       `text` (stripped review text) and `label` (integer target).\n",
    "#       Feel free to display simple counts once the frame is ready.\n",
    "raise NotImplementedError(\"Load and preprocess the review dataset.\")\n"
   ],
   "id": "f8f795c793b48210",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO: create embeddings for the cleaned `df`.\n",
    "# Expectations:\n",
    "#   * Instantiate SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "#   * Convert `df[\"text\"]` to a list for encoding and `df[\"label\"]` to a numpy float32 array.\n",
    "#   * Split into train/test with stratification, then wrap tensors inside TensorDataset/DataLoader objects\n",
    "#     named `train_loader` and `test_loader`. Keep around `X_train`, `X_test`, `y_train`, and `y_test`\n",
    "#     for the evaluation cell.\n",
    "raise NotImplementedError(\"Embed the text and create train/test splits plus DataLoaders.\")\n"
   ],
   "id": "f7c798c95122c8d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO: define a small neural net maybe one 128 hidden layer that accepts the embedding size,\n",
    "#       set up BCEWithLogitsLoss + AdamW, pick a number of epochs, and train the model with a standard\n",
    "#       PyTorch loop. Print the epoch loss so you can monitor progress.\n",
    "class ReviewClassifier(nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        return self.layers(inputs).squeeze(1)\n",
    "\n",
    "model = ReviewClassifier(X_train.shape[1])\n",
    "criterion =\n",
    "optimizer =\n",
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = epoch_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            preds = model(xb)\n",
    "            val_loss += criterion(preds, yb).item() * xb.size(0)\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss {avg_train_loss:.4f}, val_loss {avg_val_loss:.4f}\")\n",
    "\n"
   ],
   "id": "4c8b894361a293f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# TODO: switch the model to eval mode, obtain sigmoid probabilities for `X_test`,\n",
    "#       threshold them at 0.5, and compute accuracy plus a classification report.\n",
    "raise NotImplementedError(\"Evaluate the classifier on held-out data.\")\n"
   ],
   "id": "67cbb2f754904291",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
